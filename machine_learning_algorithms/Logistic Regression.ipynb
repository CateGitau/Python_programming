{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "\n",
    "Reference:\n",
    "- https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Logistic%20Regression.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In logistic regression, we are trying to model the outcome of a binary variable given a linear combination of input features. For example, we could try to predict the outcome of an election (win/lose) using information about how much money a candidate spent campaigning, how much time she/he spent campaigning, etc.\n",
    "Model\n",
    "\n",
    "Logistic regression works as follows.\n",
    "\n",
    "Given:\n",
    "\n",
    "- dataset $\\{(\\boldsymbol{x}^{(1)}, y^{(1)}), ..., (\\boldsymbol{x}^{(m)}, y^{(m)})\\}$\n",
    "- with $\\boldsymbol{x}^{(i)}$ being a $d-$dimensional vector $\\boldsymbol{x}^{(i)} = (x^{(i)}_1, ..., x^{(i)}_d)$\n",
    "- $y^{(i)}$ being a binary target variable, $y^{(i)} \\in \\{0,1\\}$\n",
    "\n",
    "The logistic regression model can be interpreted as a very simple neural network:\n",
    "\n",
    "- it has a real-valued weight vector $\\boldsymbol{w}= (w^{(1)}, ..., w^{(d)})$\n",
    "- it has a real-valued bias $b$\n",
    "- it uses a sigmoid function as its activation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training\n",
    "\n",
    "Different to linear regression, logistic regression has no closed form solution. But the cost function is convex, so we can train the model using gradient descent. In fact, gradient descent (or any other optimization algorithm) is guaranteed to find the global minimum (if the learning rate is small enough and enough training iterations are used).\n",
    "\n",
    "Training a logistic regression model has different steps. In the beginning (step 0) the parameters are initialized. The other steps are repeated for a specified number of training iterations or until convergence of the parameters.\n",
    "\n",
    "**Step 0**: Initialize the weight vector and bias with zeros (or small random values).\n",
    "\n",
    "----\n",
    "\n",
    "**Step 1**: Compute a linear combination of the input features and weights. This can be done in one step for all training examples, using vectorization and broadcasting: $\\boldsymbol{a} = \\boldsymbol{X} \\cdot \\boldsymbol{w} + b $\n",
    "\n",
    "\n",
    "where $\\boldsymbol{X}$ is a matrix of shape $(n_{samples}, n_{features})$ that holds all training examples, and $\\cdot$ denotes the dot product.\n",
    "\n",
    "----\n",
    "\n",
    "**Step 2**: Apply the sigmoid activation function, which returns values between 0 and 1:\n",
    "\n",
    "$\\boldsymbol{\\hat{y}} = \\sigma(\\boldsymbol{a}) = \\frac{1}{1 + \\exp(-\\boldsymbol{a})}$\n",
    "\n",
    "----\n",
    "\n",
    "**Step 3**: Compute the cost over the whole training set. We want to model the probability of the target values being 0 or 1. So during training we want to adapt our parameters such that our model outputs high values for examples with a positive label (true label being 1) and small values for examples with a negative label (true label being 0). This is reflected in the cost function:\n",
    "\n",
    "$J(\\boldsymbol{w},b) = - \\frac{1}{m} \\sum_{i=1}^m \\Big[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\Big]$\n",
    "\n",
    "----\n",
    "\n",
    "**Step 4**: Compute the gradient of the cost function with respect to the weight vector and bias. A detailed explanation of this derivation can be found here.\n",
    "\n",
    "The general formula is given by:\n",
    "\n",
    "$ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^m\\left[\\hat{y}^{(i)}-y^{(i)}\\right]\\,x_j^{(i)}$\n",
    "\n",
    "For the bias, the inputs $x_j^{(i)}$ will be given 1.\n",
    "\n",
    "----\n",
    "\n",
    "**Step 5**: Update the weights and bias\n",
    "\n",
    "$\\boldsymbol{w} = \\boldsymbol{w} - \\eta \\, \\nabla_w J$\n",
    "\n",
    "$b = b - \\eta \\, \\nabla_b J$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
